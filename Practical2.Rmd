---
title: "Kaminda - Practical 2"
output: html_notebook
---


```{r}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
```

```{r}
library(tidyr)
library(ggplot2)
library(scales)
```

```{r}
install.packages("tidytext")
install.packages("textstem")
install.packages("clinspacy")
install.packages("topicmodels")
install.packages("reshape2")
install.packages("stringr")
```

```{r}
library(tidytext)
library(textstem)
library(clinspacy)
library(topicmodels)
library(reshape2)
library(stringr)
```

###Data Parsing

```{r}
raw.data <- clinspacy::dataset_mtsamples()
dplyr::glimpse(raw.data)
```
**1** 

###Data Description

##NoteID - This variable is the unique ID for each note.

##Description - This output provides a summary of the SOAP notes.

##Medical_Specialty - This variable refers to the medical speciality the patient is visiting.

##Sample_Name - This variable refers to the procedures undergone for each patient.

##Transcription - This output provides a full transcript of the physicians SOAP notes.

##Keywords - This output collects keywords from the Medical_Speciality, Sample_Name, and Transcription variables.



```{r rawdata medical specialities}

raw.data %>% dplyr::select(medical_specialty) %>% dplyr::n_distinct()
```

###Transcripts per specialty

```{r}
ggplot2::ggplot(raw.data, ggplot2::aes(y=medical_specialty)) + ggplot2::geom_bar() + labs(x="Document Count", y="Medical Speciality")
```

```{r}
filtered.data <- raw.data %>% dplyr::filter(medical_specialty %in% c("Orthopedic", "Radiology", "Surgery")) 
```


###Text Processing

```{r text processing}

analysis.data <- filtered.data %>%
  unnest_tokens(word, transcription) %>%
  mutate(word = str_replace_all(word, "[^[:alnum:]]", "")) %>%
  filter(!str_detect(word, "[0-9]")) %>%
  anti_join(stop_words) %>%
  group_by(note_id) %>%
  summarise(transcription = paste(word, collapse = " ")) %>%
  left_join(select(filtered.data, -transcription), by = "note_id")
```


```{r}
tokenized.data.unigram <- analysis.data %>% tidytext::unnest_tokens(word, transcription, to_lower=TRUE)
```

```{r}
tokenized.data <- analysis.data %>% tidytext::unnest_tokens(ngram, transcription, token = "ngrams", n=2, to_lower = TRUE)
```

**2**

###Unique Tokens per Speciality

```{r token unigram}
tokenized.data.unigram %>% dplyr::group_by(medical_specialty) %>% dplyr::distinct(word) %>% dplyr::summarise(n=dplyr::n())
```
##Unique Unigrams

##There are 7682 unique unigrams in the orthopedic speciality.

##There are 5935 unique unigrams in the radiology speciality.

##There are 11977 unique unigrams in the surgery speciality.


```{r token bigram}

tokenized.data %>% dplyr::group_by(medical_specialty) %>% dplyr::distinct(ngram) %>% dplyr::summarise(n=dplyr::n())
```


```{r unigram token distribution}

word_counts <- tokenized.data.unigram %>%
    group_by(word) %>%
    summarise(count = n()) %>%
    ungroup() %>%
    arrange(desc(count))

count_distribution <- word_counts %>%
  group_by(count) %>%
  summarise(num_words = n()) %>%
  ungroup()
 
 ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
  geom_point() +
  labs(title = "Scatter Plot of Count Distribution",
       x = "Count of Unique Words",
       y = "Number of Words")
```

```{r bigram token distribution}
word_counts <- tokenized.data %>%
    group_by(ngram) %>%
    summarise(count = n()) %>%
    ungroup() %>%
    arrange(desc(count))

count_distribution <- word_counts %>%
  group_by(count) %>%
  summarise(num_words = n()) %>%
  ungroup()
 
 ggplot2::ggplot(count_distribution, aes(x = count, y = num_words)) +
  geom_point() +
  labs(title = "Scatter Plot of Count Distribution",
       x = "Count of Unique Bigrams",
       y = "Number of Words")
```

**3**
###Unique bigrams per category


```{r token bigram2}

tokenized.data %>% dplyr::group_by(medical_specialty) %>% dplyr::distinct(ngram) %>% dplyr::summarise(n=dplyr::n())
```


##Unique Bigrams

##There are 55732 unique bigrams in the orthopedic specialty.

##There are 28297 unique bigrams in the radiology speciality.

##There are 130404 unique bigrams in the surgey speciality.


**4**

##Unique Sentences

```{r sentences}
analysis.data <- filtered.data %>%
  unnest_tokens(sentence, transcription, token = "sentences") %>%
  mutate(sentence = str_replace_all(sentence, "[^[:alnum:]\\s]", "")) %>%
  filter(!str_detect(sentence, "[0-9]")) %>%
  cross_join(stop_words) %>%
  group_by(note_id) %>%
  summarise(transcription = paste(sentence, collapse = " ")) %>%
  left_join(select(filtered.data, -transcription), by = "note_id")
```

```{r}
?cross_join
```

```{r}
?str_detect
```

```{r}
tokenized.data.sentence <- analysis.data %>% tidytext::unnest_tokens(ngram, transcription, token = "sentences", to_lower = TRUE)
```

```{r}
tokenized.data.sentence %>%
  dplyr::group_by(medical_specialty) %>%
  dplyr::count(name = "n") %>%
  dplyr::ungroup()
```

##Unique Sentences

##There are 350 unique bigrams in the orthopedic specialty.

##There are 262 unique bigrams in the radiology speciality.

##There are 1085 unique bigrams in the surgey speciality.

###Words per Category

```{r}
tokenized.data %>%
  dplyr::group_by(medical_specialty) %>%
  dplyr::count(ngram, sort = TRUE) %>%
  dplyr::top_n(5)
```

**5** 

##Use of a Lemmatizer

#A general purpose lemmatizer may not work well for medical data. This is because medical data contains highly specialized terms that require accurately trained methods to be trained to accurately token terms. Some specific issues include:

#a. Medical data usually contains specialized terms, drugs names, and jargon. Therefore, a general purpose tool may not have the knowledge of these terms and may not be proficient in accurately identfying the lemmas.

#b. Medical terms typically come from different parts of speech such as nouns, verbs, and adjectives. Since the process of lemmatizing requires mapping to generate correct lemmas, general purpose lemmas (which have not been trained on medical data) may not process the variations in medical speech effectively.


```{r lemmatizer}
lemmatized.data <- tokenized.data %>% dplyr::mutate(lemma=textstem::lemmatize_words(ngram))
```


```{r}
lemma.freq <- lemmatized.data %>% 
  dplyr::count(medical_specialty, lemma) %>%
  dplyr::group_by(medical_specialty) %>% 
  dplyr::mutate(proportion = n / sum(n)) %>%
  tidyr::pivot_wider(names_from = medical_specialty, values_from = proportion) %>%
  tidyr::pivot_longer(`Surgery`:`Radiology`,
               names_to = "medical_specialty", values_to = "proportion")
```


```{r}
ggplot2::ggplot(lemma.freq, ggplot2::aes(x=proportion, 
                                         y=`Orthopedic`,
                                         color=abs(`Orthopedic` - proportion))) + 
  ggplot2::geom_abline(color="gray40", lty=2) +
  ggplot2::geom_jitter(alpha=0.1, size=2.5, width=0.3, height=0.3) +
  ggplot2::geom_text(ggplot2::aes(label=lemma), check_overlap=TRUE, vjust=1.5) +
  ggplot2::scale_x_log10(labels=scales::percent_format()) + 
  ggplot2::scale_y_log10(labels=scales::percent_format()) + 
  ggplot2::scale_color_gradient(limits=c(0, 0.001), low="darkslategray4", high="gray75") +
  ggplot2::facet_wrap(~medical_specialty, ncol = 2) +
  ggplot2::theme(legend.position="none") +
  ggplot2:: labs(y="Orthopedic", x = NULL)
```

**6**

##Analyzing relative proportions 

#This plot visualizes the same relative proportion of lemmas in each speciality. Based on these specialties, I would not expect to see the exact same relative proportions. There are some differences in the relationship between orthopaedics and radiology, and orthopaedics and surgery:

#Orthopaedics and surgery are more likely to have a high degree of common lemmas. Both specialties are based on standard anatomical terms.

#Orthopaedics and radiology are less likely to have a high degree of common lemmas. There is definitely overlap however, radiology may refer more to the technique of medical imaging. Therefore, many of the anatomical terms, diagnoses, and treatments related to orthopaedics may be missed.

**7**

##Direct comparison of surgery and radiology

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(textstem)
```


```{r}
lemmatized.data <- tokenized.data %>% dplyr::mutate(lemma=textstem::lemmatize_words(ngram))
```


```{r}
lemma.freq <- lemmatized.data %>% 
  dplyr::count(medical_specialty, lemma) %>%
  dplyr::group_by(medical_specialty) %>% 
  dplyr::mutate(proportion = n / sum(n)) %>%
  tidyr::pivot_wider(names_from = medical_specialty, values_from = proportion) %>%
  tidyr::pivot_longer(`Orthopedic`:`Radiology`,
               names_to = "medical_specialty", values_to = "proportion")
```

```{r}
ggplot2::ggplot(lemma.freq, ggplot2::aes(x=proportion, 
                                         y=`Surgery`,
                                         color=abs(`Surgery` - proportion))) + 
  ggplot2::geom_abline(color="gray40", lty=2) +
  ggplot2::geom_jitter(alpha=0.1, size=2.5, width=0.3, height=0.3) +
  ggplot2::geom_text(ggplot2::aes(label=lemma), check_overlap=TRUE, vjust=1.5) +
  ggplot2::scale_x_log10(labels=scales::percent_format()) + 
  ggplot2::scale_y_log10(labels=scales::percent_format()) + 
  ggplot2::scale_color_gradient(limits=c(0, 0.001), low="darkslategray4", high="gray75") +
  ggplot2::facet_wrap(~medical_specialty, ncol = 2) +
  ggplot2::theme(legend.position="none") +
  ggplot2:: labs(y="Surgery", x = NULL)
```

###TF-IDF Normailization

```{r lemma counts}
lemma.counts <- lemmatized.data %>% dplyr::count(medical_specialty, lemma)
total.counts <- lemma.counts %>% 
                      dplyr::group_by(medical_specialty) %>% 
                      dplyr::summarise(total=sum(n))

all.counts <- dplyr::left_join(lemma.counts, total.counts)
```

```{r}
all.counts.tfidf <- tidytext::bind_tf_idf(all.counts, lemma, medical_specialty, n) 
```

```{r}
all.counts.tfidf %>% dplyr::group_by(medical_specialty) %>% dplyr::slice_max(order_by=tf_idf, n=10)
```

**8**
##Stand out lemmas

#The lemmas that stand out in these lists are "admission", "diagnosis", "chief", and "complaint. Orthopedics often includes admission and diagnosis of patients based on their presenting complaint, so a treatment modallity can be selected.


```{r}
analysis.data %>% dplyr::select(medical_specialty, transcription) %>% dplyr::filter(stringr::str_detect(transcription, 'b.i.d')) %>% dplyr::slice(1)
```
**9**

##Extracting unusual top lemma


```{r}
analysis.data %>% dplyr::select(medical_specialty, transcription) %>% dplyr::filter(stringr::str_detect(transcription, 'atv')) %>% dplyr::slice(1)
```

###Topic Modelling

```{r topic modelling}
lemma.counts <- lemmatized.data %>% dplyr::count(note_id, lemma)
total.counts <- lemma.counts %>% 
                      dplyr::group_by(note_id) %>% 
                      dplyr::summarise(total=sum(n))

all.counts <- dplyr::left_join(lemma.counts, total.counts)

emr.dcm <- all.counts %>% tidytext::cast_dtm(note_id, lemma, n)
```

```{r}
emr.lda <- topicmodels::LDA(emr.dcm, k=5, control=list(seed=42))
emr.topics <- tidytext::tidy(emr.lda, matrix='beta')
```

```{r}
top.terms <- emr.topics %>% dplyr::group_by(topic) %>% 
  dplyr::slice_max(beta, n=10) %>%
  dplyr::ungroup() %>%
  dplyr::arrange(topic, -beta)


top.terms %>% 
  dplyr::mutate(term=tidytext::reorder_within(term, beta, topic)) %>% 
  ggplot2::ggplot(ggplot2::aes(beta, term, fill=factor(topic))) + 
    ggplot2::geom_col(show.legend=FALSE) + 
    ggplot2::facet_wrap(~ topic, scales='free')  +
    tidytext::scale_y_reordered()
```

```{r}
specialty_gamma <- tidytext::tidy(emr.lda, matrix='gamma')

# we need to join in the specialty from the note_id
note_id_specialty_mapping <- lemmatized.data %>%
  dplyr::mutate(document=as.character(note_id)) %>% 
  dplyr::select(document, medical_specialty) %>% 
  dplyr::distinct()

specialty_gamma <- dplyr::left_join(specialty_gamma, note_id_specialty_mapping)
```

```{r}
specialty_gamma %>%
  dplyr::mutate(medical_specialty = reorder(medical_specialty, gamma * topic)) %>%
  ggplot2::ggplot(ggplot2::aes(factor(topic), gamma)) +
  ggplot2::geom_boxplot() +
  ggplot2::facet_wrap(~ medical_specialty) +
  ggplot2::labs(x = "topic", y = expression(gamma))
```

**10**

##Six topic LDA

```{r}
emr.lda <- topicmodels::LDA(emr.dcm, k=6, control=list(seed=42))
emr.topics <- tidytext::tidy(emr.lda, matrix='beta')
```

```{r}
top.terms <- emr.topics %>% dplyr::group_by(topic) %>% 
  dplyr::slice_max(beta, n=10) %>%
  dplyr::ungroup() %>%
  dplyr::arrange(topic, -beta)


top.terms %>% 
  dplyr::mutate(term=tidytext::reorder_within(term, beta, topic)) %>% 
  ggplot2::ggplot(ggplot2::aes(beta, term, fill=factor(topic))) + 
    ggplot2::geom_col(show.legend=FALSE) + 
    ggplot2::facet_wrap(~ topic, scales='free')  +
    tidytext::scale_y_reordered()
```
```{r}
specialty_gamma <- tidytext::tidy(emr.lda, matrix='gamma')

# we need to join in the specialty from the note_id
note_id_specialty_mapping <- lemmatized.data %>%
  dplyr::mutate(document=as.character(note_id)) %>% 
  dplyr::select(document, medical_specialty) %>% 
  dplyr::distinct()

specialty_gamma <- dplyr::left_join(specialty_gamma, note_id_specialty_mapping)
```

```{r}
specialty_gamma %>%
  dplyr::mutate(medical_specialty = reorder(medical_specialty, gamma * topic)) %>%
  ggplot2::ggplot(ggplot2::aes(factor(topic), gamma)) +
  ggplot2::geom_boxplot() +
  ggplot2::facet_wrap(~ medical_specialty) +
  ggplot2::labs(x = "topic", y = expression(gamma))
```

```{r}
install.packages("tinytext")
```

